{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ddd8859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    # Lowercase and extract words\n",
    "    return re.findall(r\"\\b[a-zA-Z]+\\b\", text.lower())\n",
    "\n",
    "def load_and_tokenize(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    return tokenize(text)\n",
    "\n",
    "def log_likelihood(a, b, c, d):\n",
    "    \"\"\"\n",
    "    Computes log-likelihood for:\n",
    "    a = freq in text1\n",
    "    b = freq in text2\n",
    "    c = size of text1 (total tokens)\n",
    "    d = size of text2 (total tokens)\n",
    "    Based on Dunning (1993)\n",
    "    \"\"\"\n",
    "    E1 = c * (a + b) / (c + d)\n",
    "    E2 = d * (a + b) / (c + d)\n",
    "\n",
    "    # Avoid log(0)\n",
    "    if a == 0 or b == 0:\n",
    "        # still allowed but must avoid log(0)\n",
    "        a = a if a != 0 else 0.000001\n",
    "        b = b if b != 0 else 0.000001\n",
    "\n",
    "    LL = 2 * (\n",
    "        a * math.log(a / E1) +\n",
    "        b * math.log(b / E2)\n",
    "    )\n",
    "    return LL\n",
    "\n",
    "def compute_keyness(file1, file2):\n",
    "    # Load and tokenize\n",
    "    tokens1 = load_and_tokenize(file1)\n",
    "    tokens2 = load_and_tokenize(file2)\n",
    "\n",
    "    # Count words\n",
    "    freq1 = Counter(tokens1)\n",
    "    freq2 = Counter(tokens2)\n",
    "\n",
    "    total1 = sum(freq1.values())\n",
    "    total2 = sum(freq2.values())\n",
    "\n",
    "    # All unique words\n",
    "    vocab = set(freq1.keys()) | set(freq2.keys())\n",
    "\n",
    "    rows = []\n",
    "    for word in vocab:\n",
    "        a = freq1[word]\n",
    "        b = freq2[word]\n",
    "        LL = log_likelihood(a, b, total1, total2)\n",
    "\n",
    "        # Direction of keyness\n",
    "        if a/total1 > b/total2:\n",
    "            key_in = \"Text1\"\n",
    "        else:\n",
    "            key_in = \"Text2\"\n",
    "\n",
    "        rows.append([word, a, b, LL, key_in])\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"word\", \"freq_text1\", \"freq_text2\", \"log_likelihood\", \"key_in\"])\n",
    "    df = df.sort_values(\"log_likelihood\", ascending=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "995d2694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                word  freq_text1  freq_text2  log_likelihood key_in\n",
      "9092           peter          20         178       44.737150  Text1\n",
      "7754          cradle           6           3       39.365993  Text1\n",
      "10278        chirrut           5           1       36.901902  Text1\n",
      "6714            hong           6           8       31.848721  Text1\n",
      "3442            kong           6           9       30.809178  Text1\n",
      "3028    regeneration           3           0       25.367524  Text1\n",
      "5057            dude           8          42       24.913781  Text1\n",
      "703             wang           4           3       24.350832  Text1\n",
      "126          tracker           4           5       21.604997  Text1\n",
      "1327           force           9          73       21.502563  Text1\n",
      "7275            babe           5          14       20.789879  Text1\n",
      "2309     codebreaker           4           6       20.539452  Text1\n",
      "7596         monster           6          27       20.235172  Text1\n",
      "6967            finn           8          62       19.714763  Text1\n",
      "8462       seriously           6          31       18.846282  Text1\n",
      "2216           chair           4           8       18.782105  Text1\n",
      "11757         duties           3           2       18.696197  Text1\n",
      "13252           baze           3           2       18.696197  Text1\n",
      "12668     behavioral           2           0       16.911674  Text1\n",
      "13520         traits           2           0       16.911674  Text1\n",
      "4874       bachelors           2           0       16.911674  Text1\n",
      "2452        deposits           2           0       16.911674  Text1\n",
      "5269          raptor           3           4       15.924360  Text1\n",
      "6301           betty           3           5       14.929442  Text1\n",
      "1518           magic           6          52       13.681937  Text1\n",
      "11732        genetic           3           7       13.355928  Text1\n",
      "8495             kit           2           1       13.121998  Text1\n",
      "7998      generators           2           1       13.121998  Text1\n",
      "5124         sanctum           2           1       13.121998  Text1\n",
      "8128     calculation           2           1       13.121998  Text1\n",
      "7788        crystals           2           1       13.121998  Text1\n",
      "6659         breaker           2           1       13.121998  Text1\n",
      "3055       uploading           2           1       13.121998  Text1\n",
      "11935    genetically           2           1       13.121998  Text1\n",
      "13404         active           3          10       11.616046  Text1\n",
      "268    consciousness           2           2       11.425285  Text1\n",
      "7220      cuttlefish           2           2       11.425285  Text1\n",
      "603         warships           2           2       11.425285  Text1\n",
      "5514              we          87        4014       11.013489  Text1\n",
      "7581            left          10         189       10.808079  Text1\n",
      "12479     government           4          27       10.775003  Text1\n",
      "13643      atlantean           3          12       10.708041  Text1\n",
      "10247         higher           3          12       10.708041  Text1\n",
      "999            money           6          72       10.544923  Text1\n",
      "9166        tracking           4          29       10.299438  Text1\n",
      "11104           plom           2           3       10.269726  Text1\n",
      "11896         acting           2           3       10.269726  Text1\n",
      "10757      elemental           2           3       10.269726  Text1\n",
      "7821           bloom           2           3       10.269726  Text1\n",
      "4362          little           0         349       10.253575  Text2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------- RUN THE ANALYSIS --------\n",
    "file1 = \"A&SE_dialogue.txt\"\n",
    "file2 = \"ALL_non-Asian high gross film.txt\"\n",
    "\n",
    "df = compute_keyness(file1, file2)\n",
    "print(df.head(50))\n",
    "df.to_csv(\"keyness_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f48bfc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
